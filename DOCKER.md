# Docker Setup - UniPost API

Documenta√ß√£o completa para execu√ß√£o do UniPost API com **Docker Compose**, incluindo todos os recursos de **IA** e **vetoriza√ß√£o**.

## üê≥ Vis√£o Geral

O Docker Compose est√° configurado para executar:

- **API Django**: Aplica√ß√£o principal com endpoints REST
- **PostgreSQL + pgvector**: Banco de dados com suporte a vetores
- **Scripts de IA**: Web scraping, vectoriza√ß√£o e Business Brain
- **Cron Jobs**: Automa√ß√£o para sincroniza√ß√£o cont√≠nua

## üìã Pr√©-requisitos

- **Docker**: Vers√£o 20.10+
- **Docker Compose**: Vers√£o 2.0+
- **Git**: Para clonar o reposit√≥rio
- **Google Gemini API Key**: Para funcionalidades de IA

## üöÄ Quick Start

### 1. Clone e Configure

```bash
# Clone o reposit√≥rio
git clone <url-do-repositorio>
cd unipost-api

# Configure vari√°veis de ambiente
cp .env.example .env
```

### 2. Configure o .env

```env
# Database
DB_HOST=db
DB_PORT=5432
DB_USER=unipost_user
DB_PASSWORD=senha_segura_aqui
DB_NAME=unipost

# Django Superuser
DJANGO_SUPERUSER_USERNAME=admin
DJANGO_SUPERUSER_EMAIL=admin@example.com
DJANGO_SUPERUSER_PASSWORD=senha_admin_aqui

# Django Secret Key (gere uma nova)
SECRET_KEY=gere_uma_chave_secreta_forte_aqui

# ‚ú® Google Gemini API Key (OBRIGAT√ìRIO para IA)
GOOGLE_GEMINI_API_KEY=sua_chave_google_gemini

# ‚ú® ElasticSearch (OPCIONAL para Business Brain)
ELASTICSEARCH_HOST=seu_elasticsearch_host
ELASTICSEARCH_PORT=9200
ELASTICSEARCH_USERNAME=seu_usuario_es
ELASTICSEARCH_PASSWORD=sua_senha_es
ELASTICSEARCH_USE_SSL=false
ELASTICSEARCH_VERIFY_CERTS=false

# Logging
LOG_FORMAT=json
```

### 3. Obter Google Gemini API Key

1. Acesse [Google AI Studio](https://aistudio.google.com/)
2. Fa√ßa login com conta Google
3. Clique em "Get API key" ‚Üí "Create API key"
4. Copie a chave e adicione no `.env`

### 4. Execute o Sistema

```bash
# Inicie todos os servi√ßos
docker-compose up -d

# Verifique se os servi√ßos est√£o rodando
docker-compose ps

# Acompanhe os logs
docker-compose logs -f app
```

### 5. Configure o Banco

```bash
# Execute migra√ß√µes (inclui tabelas de IA)
docker-compose exec app python manage.py migrate

# Crie superusu√°rio (se n√£o foi criado automaticamente)
docker-compose exec app python manage.py createsuperuser

# Verifique instala√ß√£o do pgvector
docker-compose exec db psql -U $DB_USER -d $DB_NAME -c "\\dx"
```

### 6. Configure Automa√ß√µes (Opcional)

```bash
# Configure Business Brain para executar a cada 10 minutos
docker-compose exec app ./brain/crontab_setup.sh
```

## üóÇÔ∏è Estrutura dos Servi√ßos

### Servi√ßo `app` (Django API)

```yaml
services:
  app:
    build: .
    ports:
      - "8005:8005"          # API dispon√≠vel em localhost:8005
    env_file:
      - .env                 # Todas as vari√°veis de ambiente
    volumes:
      - ./media:/app/media   # Uploads de m√≠dia
      - ./logs:/app/logs     # Logs da aplica√ß√£o
      - ./static:/app/static # Arquivos est√°ticos
    depends_on:
      db:
        condition: service_healthy  # Aguarda banco estar pronto
```

### Servi√ßo `db` (PostgreSQL + pgvector)

```yaml
services:
  db:
    image: postgres:16.9-alpine
    environment:
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data  # Dados persistentes
      - ./backups:/backups                      # Backups
      - ./init-db.sql:/docker-entrypoint-initdb.d/init-db.sql  # ‚ú® pgvector
    ports:
      - "5437:5432"          # PostgreSQL em localhost:5437
```

## üîß Comandos Essenciais

### Gerenciamento B√°sico

```bash
# Iniciar servi√ßos
docker-compose up -d

# Parar servi√ßos
docker-compose down

# Reiniciar apenas um servi√ßo
docker-compose restart app

# Ver logs de todos os servi√ßos
docker-compose logs -f

# Ver logs apenas da API
docker-compose logs -f app

# Ver status dos servi√ßos
docker-compose ps
```

### Django Management

```bash
# Executar comandos Django
docker-compose exec app python manage.py <comando>

# Migra√ß√µes
docker-compose exec app python manage.py makemigrations
docker-compose exec app python manage.py migrate

# Shell interativo
docker-compose exec app python manage.py shell

# Coletar arquivos est√°ticos
docker-compose exec app python manage.py collectstatic

# Criar superusu√°rio
docker-compose exec app python manage.py createsuperuser
```

### Scripts de IA

```bash
# Web scraping manual
docker-compose exec app python scraping/webscraper.py

# Vetoriza√ß√£o manual
docker-compose exec app python scraping/text_vectorizer.py

# Business Brain manual
docker-compose exec app python brain/business_vectorizer.py

# Ver logs das automa√ß√µes
docker-compose exec app tail -f brain/crontab.log
```

### Banco de Dados

```bash
# Conectar ao PostgreSQL
docker-compose exec db psql -U $DB_USER -d $DB_NAME

# Backup do banco
docker-compose exec db pg_dump -U $DB_USER -d $DB_NAME > backup.sql

# Restaurar backup
docker-compose exec -T db psql -U $DB_USER -d $DB_NAME < backup.sql

# Verificar extens√£o pgvector
docker-compose exec db psql -U $DB_USER -d $DB_NAME -c "SELECT * FROM pg_extension WHERE extname = 'vector';"
```

## üìä Monitoramento e Logs

### Estrutura de Logs

```
logs/
‚îú‚îÄ‚îÄ django.log          # Logs da aplica√ß√£o Django
‚îú‚îÄ‚îÄ access.log          # Logs de acesso HTTP
‚îî‚îÄ‚îÄ error.log           # Logs de erro

scraping/
‚îú‚îÄ‚îÄ scraping.log        # Logs do web scraping
‚îî‚îÄ‚îÄ vectorizer.log      # Logs da vetoriza√ß√£o

brain/
‚îú‚îÄ‚îÄ business_brain.log  # Logs do Business Brain
‚îî‚îÄ‚îÄ crontab.log         # Logs do crontab
```

### Comandos de Monitoramento

```bash
# Logs em tempo real da API
tail -f logs/django.log

# Logs de IA
tail -f scraping/*.log brain/*.log

# Buscar erros espec√≠ficos
grep -r "ERROR" logs/ scraping/ brain/

# Monitorar embeddings sendo criados
docker-compose exec app python manage.py shell
>>> from embeddings.models import Embedding
>>> Embedding.objects.count()
```

### Health Check

```bash
# Verificar sa√∫de da API
curl http://localhost:8005/health/

# Verificar Admin Django
curl http://localhost:8005/admin/

# Testar endpoint de autentica√ß√£o
curl -X POST http://localhost:8005/api/v1/auth/login/ \
  -H "Content-Type: application/json" \
  -d '{"username":"admin","password":"sua_senha"}'
```

## üêõ Solu√ß√£o de Problemas

### Problemas Comuns

#### 1. Servi√ßo n√£o inicia

```bash
# Ver logs detalhados
docker-compose logs app

# Reconstruir imagem
docker-compose build --no-cache app
docker-compose up -d

# Verificar depend√™ncias
docker-compose exec app pip list
```

#### 2. Erro de banco de dados

```bash
# Verificar se PostgreSQL est√° rodando
docker-compose exec db pg_isready

# Verificar conex√£o
docker-compose exec app python manage.py dbshell

# Reset completo do banco
docker-compose down -v  # CUIDADO: Remove dados!
docker-compose up -d
```

#### 3. pgvector n√£o instalado

```bash
# Verificar se extens√£o est√° ativa
docker-compose exec db psql -U $DB_USER -d $DB_NAME -c "CREATE EXTENSION IF NOT EXISTS vector;"

# Recrear banco com init script
docker-compose down -v
docker-compose up -d
```

#### 4. Scripts de IA n√£o funcionam

```bash
# Verificar Google Gemini API Key
docker-compose exec app python -c "
import os
print('GOOGLE_GEMINI_API_KEY:', os.getenv('GOOGLE_GEMINI_API_KEY')[:10] + '...')
"

# Testar conex√£o com Gemini
docker-compose exec app python -c "
import google.generativeai as genai
import os
genai.configure(api_key=os.getenv('GOOGLE_GEMINI_API_KEY'))
result = genai.embed_content(model='models/embedding-001', content='teste')
print('Google Gemini funcionando!')
"
```

#### 5. Crontab n√£o executa

```bash
# Verificar se crontab est√° configurado
docker-compose exec app crontab -l

# Ver logs do crontab
docker-compose exec app tail -f brain/crontab.log

# Reconfigurar crontab
docker-compose exec app ./brain/crontab_setup.sh
```

### Limpeza e Reset

```bash
# Parar e remover containers
docker-compose down

# Remover volumes (CUIDADO: Remove dados!)
docker-compose down -v

# Remover imagens
docker-compose down --rmi all

# Reset completo
docker-compose down -v --rmi all
docker system prune -a
```

## üîß Configura√ß√µes Avan√ßadas

### Vari√°veis de Ambiente Avan√ßadas

```env
# Performance
DJANGO_DEBUG=False                    # Produ√ß√£o
DJANGO_ALLOWED_HOSTS=localhost,127.0.0.1,seu_dominio.com

# Logging avan√ßado
LOG_LEVEL=INFO                        # DEBUG, INFO, WARNING, ERROR
LOG_FORMAT=json                       # json ou plain

# Database Pool
DB_CONN_MAX_AGE=600                   # Conex√µes persistentes
DB_CONN_HEALTH_CHECKS=true            # Health check das conex√µes

# IA Settings
GEMINI_RATE_LIMIT=60                  # Requests por minuto
VECTORIZER_CHUNK_SIZE=1000            # Tamanho dos chunks
VECTORIZER_MAX_TEXT_LENGTH=2048       # Limite de texto
```

### Volumes Personalizados

```yaml
# docker-compose.override.yml
services:
  app:
    volumes:
      - ./custom_scripts:/app/scripts     # Scripts customizados
      - ./exports:/app/exports            # Exports/relat√≥rios
      - /host/path/logs:/app/logs         # Logs em local espec√≠fico
  
  db:
    volumes:
      - /host/path/postgres:/var/lib/postgresql/data  # DB em local espec√≠fico
```

### Networking Customizado

```yaml
# docker-compose.override.yml
services:
  app:
    networks:
      - unipost-network
      - external-network                 # Rede externa
    expose:
      - 8005
    # ports: []                          # Remove exposi√ß√£o p√∫blica
  
  nginx:                                # Proxy reverso
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - app

networks:
  external-network:
    external: true
```

## üìà Performance e Escalabilidade

### Otimiza√ß√µes de Performance

```yaml
# docker-compose.prod.yml
services:
  app:
    deploy:
      replicas: 3                       # M√∫ltiplas inst√¢ncias
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    environment:
      - DJANGO_DEBUG=False
      - LOG_LEVEL=WARNING
  
  db:
    command: >
      postgres
      -c max_connections=200
      -c shared_buffers=256MB
      -c effective_cache_size=1GB
      -c work_mem=4MB
```

### Cache e Redis

```yaml
# Adicionar ao docker-compose.yml
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - unipost-network
    restart: unless-stopped

volumes:
  redis_data:
    driver: local
```

## üöÄ Deploy e Produ√ß√£o

### Docker Compose para Produ√ß√£o

```bash
# Usar arquivo espec√≠fico de produ√ß√£o
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d

# Build de produ√ß√£o
docker-compose -f docker-compose.prod.yml build --no-cache

# Deploy com zero downtime
docker-compose -f docker-compose.prod.yml up -d --scale app=3
```

### Backup Automatizado

```bash
# Adicionar ao crontab do host
0 2 * * * docker-compose exec -T db pg_dump -U $DB_USER -d $DB_NAME | gzip > /backups/unipost_$(date +\%Y\%m\%d).sql.gz
```

---

**Docker Setup UniPost API üê≥ - Intelig√™ncia Artificial em container!**
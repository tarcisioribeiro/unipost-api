# Sistema de Embeddings - UniPost API

Sistema avan√ßado de **intelig√™ncia artificial** e **busca sem√¢ntica** para gerenciamento e vetoriza√ß√£o autom√°tica de conte√∫do.

## ü§ñ Vis√£o Geral

O sistema de embeddings do UniPost API utiliza **Google Gemini** para converter texto em vetores matem√°ticos (embeddings) de alta dimensionalidade, permitindo:

- **Busca sem√¢ntica**: Encontrar conte√∫do por significado, n√£o apenas palavras-chave
- **An√°lise de similaridade**: Identificar conte√∫do relacionado automaticamente  
- **Categoriza√ß√£o inteligente**: Agrupar conte√∫do por contexto e tema
- **Recomenda√ß√µes**: Sugerir conte√∫do relevante baseado em similaridade

## üìä Origens de Embeddings

### 1. üåê **WebScraping** (`origin="webscraping"`)
- **Fonte**: Sites de refer√™ncia cadastrados no modelo `Site`
- **Processo**: `webscraper.py` ‚Üí `text_vectorizer.py` ‚Üí Banco
- **Frequ√™ncia**: Manual ou agendada
- **Metadados**: URL, categoria, data de scraping

### 2. ‚úçÔ∏è **Generated** (`origin="generated"`)  
- **Fonte**: Posts criados pelos usu√°rios no modelo `Text`
- **Processo**: **Autom√°tico via Django Signal**
- **Frequ√™ncia**: **Instant√¢neo** (ao criar/atualizar post)
- **Metadados**: Plataforma, tema, ID do texto, aprova√ß√£o

### 3. üß† **Business Brain** (`origin="business_brain"`)
- **Fonte**: Dados corporativos do ElasticSearch externo
- **Processo**: `business_vectorizer.py` via **crontab (10 minutos)**
- **Frequ√™ncia**: **Autom√°tica** e cont√≠nua
- **Metadados**: √çndice ES, documento ID, score

## üóÑÔ∏è Modelo de Dados

### Estrutura do Embedding

```python
class Embedding(models.Model):
    id = models.UUIDField(primary_key=True)           # UUID √∫nico
    origin = models.CharField(max_length=20)          # Origem dos dados
    content = models.TextField()                      # Texto original
    title = models.CharField(max_length=500)          # T√≠tulo descritivo
    embedding_vector = models.JSONField()             # Vetor Gemini (1536 dim)
    metadata = models.JSONField(default=dict)         # Metadados enriquecidos
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
```

### Escolhas de Origem

```python
ORIGIN_CHOICES = (
    ('webscraping', 'WebScraping'),      # Sites externos
    ('generated', 'Generated'),          # Posts dos usu√°rios  
    ('business_brain', 'Business Brain') # ElasticSearch corporativo
)
```

## üîÑ Fluxos de Vetoriza√ß√£o

### Fluxo 1: Posts de Usu√°rio (Autom√°tico)

```mermaid
graph LR
    A[Usu√°rio cria post] --> B[Django Signal detecta]
    B --> C[Google Gemini gera embedding]
    C --> D[Salva automaticamente]
```

**Processo detalhado:**
1. Usu√°rio cria/atualiza post no modelo `Text`
2. Signal `post_save` √© disparado automaticamente
3. Fun√ß√£o `create_embedding_on_text_save` √© executada
4. Google Gemini gera embedding do conte√∫do
5. Embedding √© salvo com `origin="generated"`

### Fluxo 2: Web Scraping (Manual/Agendado)

```mermaid
graph LR
    A[Sites cadastrados] --> B[webscraper.py]
    B --> C[JSONs tempor√°rios]
    C --> D[text_vectorizer.py]
    D --> E[Embeddings salvos]
```

**Processo detalhado:**
1. Admin cadastra sites de refer√™ncia
2. `webscraper.py` coleta conte√∫do usando MCP
3. Dados salvos em JSONs tempor√°rios
4. `text_vectorizer.py` processa JSONs
5. Gera embeddings e salva com `origin="webscraping"`
6. JSONs s√£o removidos ap√≥s processamento

### Fluxo 3: Business Brain (Autom√°tico)

```mermaid
graph LR
    A[ElasticSearch] --> B[Crontab 10min]
    B --> C[business_vectorizer.py]
    C --> D[Embeddings salvos]
```

**Processo detalhado:**
1. Crontab executa a cada 10 minutos
2. `business_vectorizer.py` conecta no ElasticSearch
3. Descobre todos os √≠ndices automaticamente
4. Processa apenas documentos novos (incremental)
5. Gera embeddings e salva com `origin="business_brain"`

## üõ†Ô∏è Configura√ß√£o e Uso

### Pr√©-requisitos

```env
# Google Gemini API Key (obrigat√≥rio)
GOOGLE_GEMINI_API_KEY=sua_chave_google_gemini

# ElasticSearch (opcional - para Business Brain)
ELASTICSEARCH_HOST=localhost
ELASTICSEARCH_PORT=9200
ELASTICSEARCH_USERNAME=
ELASTICSEARCH_PASSWORD=
```

### Instala√ß√£o

```bash
# Depend√™ncias j√° inclu√≠das no requirements.txt
pip install google-generativeai==0.8.3
pip install elasticsearch==8.16.0
pip install pgvector==0.4.1

# PostgreSQL com pgvector
docker-compose up -d  # J√° configurado no projeto
```

## üìö API REST

### Listar Embeddings

```http
GET /api/v1/embeddings/
Authorization: Bearer seu_token

# Filtros dispon√≠veis (query parameters):
?origin=webscraping     # Apenas web scraping
?origin=generated       # Apenas posts de usu√°rios  
?origin=business_brain  # Apenas dados corporativos
```

### Visualizar Embedding Espec√≠fico

```http
GET /api/v1/embeddings/{uuid}/
Authorization: Bearer seu_token
```

**Resposta exemplo:**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "origin": "generated",
  "content": "Conte√∫do do post sobre marketing digital...",
  "title": "Facebook: Marketing Digital",
  "embedding_vector": [0.123, -0.456, 0.789, ...],
  "metadata": {
    "platform": "FCB",
    "platform_display": "Facebook",
    "theme": "Marketing Digital", 
    "text_id": 42,
    "is_approved": true,
    "auto_generated": true,
    "signal_triggered": true
  },
  "created_at": "2025-01-01T10:00:00Z",
  "updated_at": "2025-01-01T10:00:00Z"
}
```

### Criar Embedding Manual (Raro)

```http
POST /api/v1/embeddings/
Authorization: Bearer seu_token
Content-Type: application/json

{
  "origin": "webscraping",
  "content": "Texto para vetorizar...",
  "title": "T√≠tulo descritivo",
  "embedding_vector": [/* vetor de 1536 dimens√µes */],
  "metadata": {
    "custom_field": "valor"
  }
}
```

## üîç Monitoramento e Analytics

### Verificar Status dos Embeddings

```bash
python manage.py shell

>>> from embeddings.models import Embedding
>>> from django.db.models import Count

# Contar por origem
>>> Embedding.objects.values('origin').annotate(count=Count('id'))
[{'origin': 'webscraping', 'count': 150},
 {'origin': 'generated', 'count': 89}, 
 {'origin': 'business_brain', 'count': 1247}]

# √öltimos embeddings criados
>>> Embedding.objects.order_by('-created_at')[:5]

# Embeddings por per√≠odo
>>> from datetime import datetime, timedelta
>>> yesterday = datetime.now() - timedelta(days=1)
>>> Embedding.objects.filter(created_at__gte=yesterday).count()
```

### Logs e Monitoramento

```bash
# Logs dos Django Signals (posts autom√°ticos)
tail -f logs/django.log | grep "create_embedding_on_text_save"

# Logs de web scraping
tail -f scraping/vectorizer.log

# Logs do Business Brain
tail -f brain/business_brain.log

# Todos os logs de embeddings
find . -name "*.log" -exec grep -l "embedding" {} \;
```

## ‚öôÔ∏è Configura√ß√µes Avan√ßadas

### Django Signals (Auto-vetoriza√ß√£o)

Localiza√ß√£o: `texts/signals.py`

```python
# Configura√ß√µes do signal
@receiver(post_save, sender=Text)
def create_embedding_on_text_save(sender, instance, created, **kwargs):
    # S√≥ processa se foi criado OU atualizado e aprovado
    should_process = created or (not created and instance.is_approved)
    
    # Evita duplicatas
    existing_embedding = Embedding.objects.filter(
        origin='generated',
        metadata__text_id=instance.id
    ).first()
```

### Chunking de Texto

Para textos grandes, o sistema divide automaticamente:

```python
# Configura√ß√£o em text_vectorizer.py
chunk_size = 1000      # caracteres por chunk
overlap = 100          # sobreposi√ß√£o entre chunks
max_text_length = 2048 # limite da API Gemini
```

### Metadados por Origem

#### WebScraping
```json
{
  "site_name": "TechCrunch",
  "site_url": "https://techcrunch.com",
  "category": "NOTICIAS", 
  "scraped_at": "2025-01-01T10:00:00Z",
  "chunk_index": 0,
  "total_chunks": 1,
  "processed_at": "2025-01-01T10:05:00Z"
}
```

#### Generated (Posts)
```json
{
  "platform": "FCB",
  "platform_display": "Facebook",
  "theme": "Marketing Digital",
  "text_id": 42,
  "is_approved": true,
  "created_at": "2025-01-01T09:00:00Z",
  "updated_at": "2025-01-01T09:30:00Z",
  "auto_generated": true,
  "signal_triggered": true
}
```

#### Business Brain (ElasticSearch)
```json
{
  "elasticsearch_id": "doc_456",
  "elasticsearch_index": "company_logs",
  "elasticsearch_score": 1.0,
  "document_hash": "abc123def456",
  "source_fields": ["message", "@timestamp", "level"],
  "processed_at": "2025-01-01T11:00:00Z",
  "original_source": { /* documento original */ }
}
```

## üöÄ Busca Sem√¢ntica (Implementa√ß√£o Futura)

### Conceito

```python
def semantic_search(query_text, origin=None, limit=10):
    """
    Busca sem√¢ntica usando similaridade de cosseno
    """
    # 1. Gerar embedding da consulta
    query_embedding = generate_embedding(query_text)
    
    # 2. Buscar embeddings similares usando pgvector
    # SELECT *, embedding_vector <-> %s AS distance 
    # FROM embeddings 
    # ORDER BY distance 
    # LIMIT %s
    
    return similar_embeddings
```

### API de Busca (Futuro)

```http
POST /api/v1/ai/search/
{
  "query": "marketing digital para redes sociais",
  "origin": "generated",  # opcional
  "limit": 10
}

# Resposta:
{
  "query": "marketing digital para redes sociais",
  "results": [
    {
      "embedding": { /* dados do embedding */ },
      "similarity_score": 0.95,
      "distance": 0.05
    }
  ]
}
```

## üêõ Solu√ß√£o de Problemas

### Problemas Comuns

#### 1. Embeddings n√£o s√£o criados automaticamente
```bash
# Verificar se signal est√° funcionando
python manage.py shell
>>> from texts.models import Text
>>> text = Text.objects.create(theme="Teste", platform="FCB", content="Teste")
>>> # Verificar logs para erros
```

#### 2. API Key Google Gemini inv√°lida
```bash
# Testar API Key
python -c "
import google.generativeai as genai
import os
genai.configure(api_key=os.getenv('GOOGLE_GEMINI_API_KEY'))
result = genai.embed_content(model='models/embedding-001', content='teste')
print('API Key v√°lida!')
"
```

#### 3. pgvector n√£o instalado
```sql
-- No PostgreSQL
\dx                    -- Listar extens√µes
CREATE EXTENSION vector;  -- Instalar se necess√°rio
```

#### 4. ElasticSearch n√£o conecta
```bash
# Testar conex√£o
curl -X GET "localhost:9200/_cluster/health"
```

### Logs de Debug

```bash
# Ativar debug logging
export DJANGO_LOG_LEVEL=DEBUG

# Ver todos os logs de embedding
grep -r "embedding" logs/

# Verificar execu√ß√£o dos signals
python manage.py shell
>>> import logging
>>> logging.basicConfig(level=logging.DEBUG)
>>> # Criar um post e observar logs
```

## üìà Performance e Otimiza√ß√£o

### √çndices de Banco

```sql
-- √çndices para busca eficiente
CREATE INDEX idx_embedding_origin ON embeddings (origin);
CREATE INDEX idx_embedding_created_at ON embeddings (created_at);

-- √çndice vetorial para busca sem√¢ntica (futuro)
CREATE INDEX idx_embedding_vector ON embeddings 
USING ivfflat (embedding_vector vector_cosine_ops) 
WITH (lists = 100);
```

### Monitoramento de Performance

```python
# Contar embeddings por dia
from django.db.models import Count, TruncDate
Embedding.objects.annotate(
    date=TruncDate('created_at')
).values('date').annotate(
    count=Count('id')
).order_by('-date')
```

## üîÆ Roadmap Futuro

### Funcionalidades Planejadas

- **Busca Sem√¢ntica Completa**: API de busca por similaridade
- **Clustering Autom√°tico**: Agrupamento de conte√∫do similar
- **Recomenda√ß√µes**: Sugest√£o de conte√∫do baseado em hist√≥rico
- **An√°lise de Sentimento**: Classifica√ß√£o autom√°tica de humor/tom
- **Multi-idioma**: Suporte a embeddings em m√∫ltiplos idiomas
- **Cache Inteligente**: Cache de embeddings frequentemente acessados
- **API GraphQL**: Interface GraphQL para consultas complexas

### Melhorias T√©cnicas

- **Batch Processing**: Processar m√∫ltiplos textos simultaneamente
- **Queue System**: Fila para processamento ass√≠ncrono
- **Vector Database**: Migra√ß√£o para banco vetorial especializado
- **Model Versioning**: Suporte a m√∫ltiplas vers√µes de modelos
- **A/B Testing**: Testes com diferentes modelos de embedding

---

**Sistema de Embeddings UniPost API ü§ñ - Intelig√™ncia Artificial ao seu alcance!**